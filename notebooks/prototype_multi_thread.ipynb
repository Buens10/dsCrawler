{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrabu Prototype (for a List of Shipment Numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for creating a prototype of the Scrabu project. The goal is to download DHL pages for a specific shipment number and scrap the shipment information from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s: %(message)s', level=logging.INFO, datefmt='%I:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate a list of shipment numbers with the check digit calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_shipment_numbers(shipment_number=None, size=2): #340434188193324407\n",
    "    logger.info(\"Generating shipment numbers with seed: {}\".format(shipment_number))\n",
    "    import numpy as np\n",
    "    from functools import reduce\n",
    "    multiplier = [3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3]\n",
    "    shipment_numbers_list = []\n",
    "    for i in range(0, size):\n",
    "        shipment_number = (shipment_number // 10) + 1\n",
    "        shipment_number_l = list(map(int, str(shipment_number)))\n",
    "        multiply_number = np.multiply(multiplier, shipment_number_l)\n",
    "        sum = reduce(lambda x, y: x+y, multiply_number)\n",
    "        pz = (10 - sum % 10)\n",
    "        shipment_number_l.append(0 if pz==10 else pz)\n",
    "        shipment_number = reduce(lambda x,y: x * 10 + y, shipment_number_l)\n",
    "        shipment_number_str = str(shipment_number).rjust(20, '0')\n",
    "        shipment_numbers_list.append(shipment_number_str)\n",
    "    logger.info(\"Generated {} unique shipment numbers\".format(len(set(shipment_numbers_list))))\n",
    "    return shipment_numbers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:06:42 INFO: Generating shipment numbers with seed: 340434188193323500\n",
      "03:06:42 INFO: Generated 50 unique shipment numbers\n"
     ]
    }
   ],
   "source": [
    "shipment_numbers = generate_shipment_numbers(shipment_number=340434188193323500, size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the HTML content for a list of shipment numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def request(shipment_number=None, start_url=\"https://www.dhl.de/int-verfolgen/search?language=de&lang=de&domain=de&piececode=\"):\n",
    "    import requests\n",
    "    import numpy as np\n",
    "    logger.debug(\"Making HTTP request for shipment number {}\".format(shipment_number))\n",
    "    request_url = start_url + str(shipment_number)\n",
    "    return requests.get(request_url).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_response = request(shipment_number=\"00340434188193323500\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing HTML and converting it into JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_to_json(html):\n",
    "    from lxml import etree\n",
    "    import json\n",
    "    logger.debug(\"Converting HTML to JSON\")\n",
    "    \n",
    "    html_tree = etree.HTML(html)\n",
    "    \n",
    "    def clean_json(dirty_json):\n",
    "        start = dirty_json.find('JSON.parse(')\n",
    "        end = dirty_json.find('\"),', start)\n",
    "        cjson = dirty_json[start:end]\n",
    "        cjson = cjson.replace('JSON.parse(\"', '')\n",
    "        cjson = cjson.replace('\\\\', '')\n",
    "        return cjson\n",
    "    \n",
    "    def find_json_element(html_tree):\n",
    "        json_element = html_tree.xpath('//div')\n",
    "        return str(etree.tostring(json_element[0]))\n",
    "    \n",
    "    dirty_json = find_json_element(html_tree)\n",
    "    json_string = clean_json(dirty_json)\n",
    "    return json.loads(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipment_details_json = html_to_json(html_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structure the shipment details in JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def shipment_details(shipment_details_json, start_url=\"https://www.dhl.de/int-verfolgen/search?language=de&lang=de&domain=de&piececode=\", shipment_number=\"00340434188193323500\"):\n",
    "    import datetime\n",
    "    logger.debug(\"Preparing JSON for persistance\")\n",
    "    delivery_history_dict = {}\n",
    "    delivery_history_dict[\"shipment_number\"] = shipment_details_json[\"sendungen\"][0][\"sendungsdetails\"][\"sendungsnummern\"].get(\"sendungsnummer\")\n",
    "    delivery_history_dict[\"crawltime\"] = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    delivery_history_dict[\"url\"] = start_url + str(shipment_number) \n",
    "    delivery_history_dict[\"events\"] = shipment_details_json[\"sendungen\"][0][\"sendungsdetails\"][\"sendungsverlauf\"].get(\"events\", [])\n",
    "    return delivery_history_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipment_history = shipment_details(shipment_details_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def save_dictionary(shipment_history=None, filename=None):\n",
    "    logger.info(\"Writing file {}\".format(filename))\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(shipment_history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:06:59 INFO: Writing file ../data/00340434188193323500.json\n"
     ]
    }
   ],
   "source": [
    "save_dictionary(shipment_history=None, filename=\"../data/00340434188193323500.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main function, which goes through all shipment numbers and uses the previous methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-235-205e7ea3940c>, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-235-205e7ea3940c>\"\u001b[0;36m, line \u001b[0;32m21\u001b[0m\n\u001b[0;31m    for future in concurrent.futures.as_completed(futures_to_url):\u001b[0m\n\u001b[0m                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from concurrent import futures\n",
    "from concurrent.futures import ThreadPoolExecutor as PoolExecutor\n",
    "def main(shipment_number=None, size=None, start_url=\"https://www.dhl.de/int-verfolgen/search?language=de&lang=de&domain=de&piececode=\"):\n",
    "    shipment_numbers = generate_shipment_numbers(shipment_number=shipment_number, size=size)\n",
    "    count_saved = 0\n",
    "    def process_data():\n",
    "        for shipment_number in shipment_numbers:\n",
    "            time.sleep(0.5)\n",
    "            html_response = request(shipment_number=shipment_number)\n",
    "            shipment_details_json = html_to_json(html_response)\n",
    "            shipment_history = shipment_details(shipment_details_json, shipment_number=shipment_number)\n",
    "            if len(shipment_history['events']) > 0:\n",
    "                save_dictionary(shipment_history, filename=\"../data/{}.json\".format(shipment_number))\n",
    "                count_saved = count_saved + 1\n",
    "            else:\n",
    "                logger.info(\"No events found for shipment number {}\".format(shipment_number))\n",
    "            start_index = start_index + 1\n",
    "    with PoolExecutor(max_workers=4) as executor:\n",
    "        futures_to_url = [executor.submit(process_data, request_url)\n",
    "        for future in concurrent.futures.as_completed(futures_to_url):\n",
    "            url = future_to_url[future]\n",
    "            try:\n",
    "                data = future.result()\n",
    "            except Exception as exc:\n",
    "                print('%r generated an exception: %s' % (url, exc))\n",
    "            else:\n",
    "                print('%r page is %d bytes' % (url, len(data)))\n",
    "                \n",
    "        logger.info(\"Saved {} files out of {}\".format(count_saved, size))\n",
    "    end = time.time()\n",
    "    diff = end - start\n",
    "    print(diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:12:10 INFO: Generating shipment numbers with seed: 340434188193323500\n",
      "03:12:10 INFO: Generated 100 unique shipment numbers\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'future_to_url' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-236-a8488ea056e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshipment_number\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m340434188193323500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-233-20ee1ff88679>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(shipment_number, size, start_url)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mfutures_to_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;32mfor\u001b[0m \u001b[0mrequest_url\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhtml_response\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_completed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures_to_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mrequest_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture_to_url\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'future_to_url' is not defined"
     ]
    }
   ],
   "source": [
    "main(shipment_number=340434188193323500, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import urllib.request\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "URLS = ['http://www.foxnews.com/',\n",
    "        'http://www.cnn.com/',\n",
    "        'http://europe.wsj.com/',\n",
    "        'http://www.bbc.co.uk/']\n",
    "\n",
    "# Retrieve a single page and report the URL and contents\n",
    "def load_url(url, timeout):\n",
    "    with urllib.request.urlopen(url, timeout=timeout) as conn:\n",
    "        time.sleep(10)\n",
    "        return conn.read()\n",
    "\n",
    "# We can use a with statement to ensure threads are cleaned up promptly\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=40) as executor:\n",
    "    # Start the load operations and mark each future with its URL\n",
    "    future_to_url = {executor.submit(load_url, url, 60): url for url in URLS}\n",
    "    for future in concurrent.futures.as_completed(future_to_url):\n",
    "        url = future_to_url[future]\n",
    "        try:\n",
    "            data = future.result()\n",
    "        except Exception as exc:\n",
    "            print('%r generated an exception: %s' % (url, exc))\n",
    "        else:\n",
    "            print('%r page is %d bytes' % (url, len(data)))\n",
    "    \n",
    "end = time.time()\n",
    "diff = end - start\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
